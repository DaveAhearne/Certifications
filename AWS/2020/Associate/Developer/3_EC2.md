# Beginners Guide to EC2 (Elastic Compute Cloud)

## EC2 101
Elastic Compute Cloud or EC2 is a web service that **provides virtual machines on demand in the cloud** meaning you can get new machines in minutes rather than the days and weeks of ordering physical hardware in the days of old

You can scale in two major ways with EC2:
* Horizontally - By spinning up new instances of EC2 to deal with load
* Vertically - By changing their type to give them access to more performant hardware

EC2 changes the game in terms of economics *you pay for what you need right now* rather than going out and making a big capex purchase all in one go including what you assume potential future use will be *(Prevents Overprovisioning)*

### Pricing Options
There are few different ways of paying for EC2 depending on how much stability you want, these are:
* On Demand - You pay a fixed rate by the hour/second and *you don't make any commitments in terms of time or use*
* Reserved - Reserves capacity for you, you enter into a contract with Amazon about how long you will keep the EC2 around for and in exchange you get a discount depending on the length of the contract of 1 to 3 years with a variable amount upfront *(Longer term = greater discount)*
* Spot - You bid on instance capacity like a stock market, if your workload supports this kind of flexibility in terms of being able to be turned on/off randomly but you want to save money this is a good option **however there is no guarantee that your workload will be run if your bid price is too low**
* Dedicated Hosts - A physical EC2 server that is dedicated for your use, these are typically used to conform to existing server-bound licence agreements for software

Windows instances are typically priced by the hour, Linux instances are typically by the second *however this may change*

On-Demand is typically good for users that want *flexibility* who *dont want long term costs* or support so things like running up a lot of machines for testing something *that can't be stopped or interrupted* or prototyping building software for example

Reserved is good if you have *long term stable load* this makes it good for things like a stock of *base web servers* with extra being on demand to cope with spikey load for example. Entering into a contract means that you *can reduce your overall cost for the length of the contract* - You can also have convertible reserved instance meaning that *you can change attributes of the virtual machine, as long as it results in the creation of an instance of equal or greater value* e.g. A very CPU intensive machine to a very memory intensive machine. With reserved you can also have **Sheduled Reserved Instances** where you reserve machines *for a specific time window* for example a holiday week/day or particular event such as the World Cup

Spot instances are *for applications that can have variable start and end times*, typically for tasks that can be broken up into very small scale steps that can be started and stopped whenever. This is typically *for applications that are only feasible at very low compute costs* e.g. Genomics, Pharmaceutical companies, Chemical companies, Bitcoin mining at 3am on a Sunday morning

**If a spot instance is terminated by EC2, you are NOT charged for the partial hour - If you terminate the instance yourself you will be charged for the complete hour**

Dedicated hosts are typically used for *regulatory requirements or licencing agreements for software* where you pay by the server, or you want to garentee your own hardware *to prevent noisy neighbours stealing your I/O* or for *legal reasons e.g. not being allowed to use multi-tenant virtualization*, it **can be purchased on demand, or as a reservation**

### EC2 Instance Types
You **do not** need to memorize all of these for the associate exams (Some of the higher tier ones you may do depending on specialization), but there are a few that are typically used fairly often

**The number next to the letter refers to the generation, the letter refers to the type**, you won't ever be tested on the generation of the machines, just their types

| Family | Speciality                    | Use Case                                                           |
|--------|-------------------------------|--------------------------------------------------------------------|
| F1     | Field Programmable Gate Array | Genomics Research, financial analytics, real time video processing |
| I3     | High speed storage            | NoSQL DBs, DBs, Data wharehousing                                  |
| G3     | Graphics intensive            | Video encoding/3D application streaming                            |
| H1     | High disk throughput          | MapReduce, distributed filesystems like HDFS                       |
| T2     | Lowest cost, general purpose  | Web server and small databases                                     |
| D2     | Dense storage                 | Fileservers, Data wharehousing, Hadoop                             |
| R4     | Memory optimized              | Memory intensive apps or databases                                 |
| M5     | General purpose               | Application servers                                                |
| C5     | Compute optimized             | CPU intensive applications or databases                            |
| P3     | Graphics/General purpose GPU  | Machine learning or Bitcoin Mining                                 |
| X1     | Memory Optimized              | SAP HANA, Apache Spark, etc.                                       |

A good mnemonic for remembering them is FIGHT DR MC PX, imagine fighting a scottish doctor that wants to give you photos of his holiday

### EBS (Elastic Block Storage)

EBS or **Elastic Block Storage is Amazon's equivalent of virtual hard disks**, you can treat these as normal hard disks in terms of creating a filesystem on then, running a database etc. You use them by *attaching them to an EC2 Instance*, **EBS Volumes get spread across an Availability Zone and replicated to prevent you from losing data due to a hardware failure**

The EBS that is attached to your EC2 instance where the operating system is installed is called the **root device volume**, but you can add other drives on top of that one

The types of EBS volumes are:
* General Purpose SSD (GP2) - Middle of the road cost/performance SSD, *3 IOPS per GB up to 10,000* and burst to 3000 IOPS for drives larger than 3.3TB
* Provisioned IOPS SSD (IO1) - For I/O intensive applications e.g. databases, *to be used if you need more than 10,000 IOPS*, can provision *up to 20,000 IOPS*
* Throughput Optimized HDD (ST1) - Magnetic Non-SSD, used for big data/data wharehousing/log processing etc, **Cannot be a boot volume/root device volume**
* Cold HDD (SC1) - Magnetic Non-SSD, Lowest cost for infrequently accessed workloads, used for a file server, **Cannot be a boot volume/root device volume**
* Magnetic (Standard) - Magnetic Non-SSD, *Lowest cost of all EBS volumes*, good for a cost critical design on an infrequently accessed workload **Is the only bootable magnetic EBS type, however its a legacy type**

## EC2 Lab

The first thing you'll want to do before you start creating EC2's and other resources is to go to the top right hand corner of the AWS Console and *change the region to something thats geographically close to you* in order to reduce latency. *If you want the latest features do your work in N.Virginia*, however bear in mind that **different reigeons may have different prices for services**

### To set up a basic EC2 instance
1. Go to the EC2 dashboard from the AWS Console
2. Click the "Launch Instance" button

Instances are created from **Amazon Machine Images** or AMI's, these are a bunch of different disk images loaded with various operating systems and some are pre-loaded with software set up and configured for you, *some of them cost money in licencing whereas others are free to use*

The main list are the images that Amazon themselves maintain, however if you look on the tab to the left hand side you will see **AWS Marketplace** and **Community AMI's** these are third party AMI's and Community submitted AMI's that you can choose that may incur a cost

3. Choose the Amazon Linux AMI - This is an image created by Amazon that includes some basic tooling on a linux environment that is free to use from a licencing perspective

4. Choose the instance type - This is when we choose what instance family we want to use from the letters from before to suit our workload

5. Configure the instance details - Here we change details about *how* the EC2 will run such as details about enabling spot pricing, how many instances you want to spin up, networking details for the machine, IAM roles it should run under etc.

6. Select any extra storage we'd like to add - Here at the top we can see and change our root device volume to any one of the other bootable types or change its size, we can also add additional drives with "Add New Volume"

7. Add tags - Tags are an optional step that lets you tag your resources with details that help organise and view them later on so you can ask questions like "What resources is this project using?", "How many EC2's has the dev team created?"

8. Configure Security Groups - **Security groups are a virtual firewall** in that on top of the existing virtual network protection we can also define rules that say what services can talk inbound or outbound to our machine on what ports, *You can also restrict the ports by IP access to certain ranges or just your IP*

9. Press Review and launch, make sure that you're happy and then click "Launch"

10. You will be prompted to create a key pair or select an existing one - This is the **public/private key set that will be used to connect to the running EC2 instance** this means that *only you with the private key can connect to this EC2 instance*, give the key pair a name if creating one and download the key pair **STORE THIS SECURELY, ANYONE WHO OBTAINS THIS PRIVATE KEY CAN LOG ONTO THE SERVER IF THE PORTS ALLOW IT**

*Remember: With public/private key auth, you can hand out your public key to anyone, but always keep the private key safe*

11. Hit launch instance to create the instance with the private key set and configuration parameters we defined

### Managing a basic EC2 instance

After we've created our EC2 instance, if we go to the instances tab on the left hand side we will be able to see a row in the table for our instance creating, it will be in the state of *"pending"* until it's finished booting up at which point it will become *"active"* and we can connect to it

To connect to the running EC2 instance via SSH:
1. Go to the instances list on the left hand side of the EC2 homepage
2. Select which instance you'd like to connect to
3. Click the connect button next to launch instance at the top of the screen
4. Choose "A standalone SSH client"
5. Follow the on-screen instructions and provide the .pem file you created when initializing the EC2 instance to securely connect to the machine

Typically, if you've just created an EC2 server - You will want to patch it with the latest updates before you start using it, to do that connect to it via SSH as above and if you're using the AWS Amazon Linux AMI run the following command:
```
    yum update -y
```

This will update all of the software on the system and automatically approve any prompts, bear in mind that while the AMI's are updated fairly regularily you will need to maintain updates yourself once you use one


## Elastic Load Balancer

**An Elastic Load Balancer helps us balance load across multiple different servers**, for instance if we had three seperate servers to help handle website traffic and we wanted to spread traffic from the internet equally accross them. *The reason for doing this is so that you don't get one server being overwhelmed with requests* or need to provision a single super machine to be able to handle all of the requests

There are three main types of load-balancer:
* Application Load Balancer - OSI Layer 7 (Application Network Layer), **can make clever descisions** about application level traffic *e.g. Do packets contain content bound for the ordering system? Send it there instead*, they're **built for load-balancing HTTP and HTTPS traffic**
* Network Load Balancer - OSI Layer 4 (Transport Layer), dumber than the application load balancer and can't make as smart decisions because it doesn't have the information **but it can do things very quickly** however its also **AWS's most expensive load balancer** but its typically what you would use if latency or performance is critical to you, **network Load Balancers can handle millions of requests per second**
* Classic Load Balancer - Not Reccomended to use, **the exam tests you mostly based on classic load balancers, even though AWS recccomend you don't use them** you can load balance on HTTP/S traffic and **can hook into layer 7 specific features (e.g. X-Forwarded), or use strict layer 4 years for load balancing TCP**, however the Layer 7 stuff you can do in this isn't anywhere near as complex or fast as the dedicated Application Load Balancer

If your application or what you have sitting behind the load-balancer stops responding or working **the load-balancer itself will respond with 504 Gateway Timeout**, if you see this your application behind has gone bang

If you have an application sitting behind a load-balancer, it recieves the IP address that it's called with which will be the IP or the load-balancer, **if you need the actual IP address of the entity that called the load-balancer its passed in the X-Forwarded-For header**

## Route53 Lab

**Route53 is Amazons Domain Name Service** its name comes from the port that DNS queries use, 53. *It allows you to map domain names to AWS services* such as EC2 Instances, Load balancers and S3 Buckets, you're able to buy domain names from within this service because *AWS operates its own domain registry*

### To buy a domain in Route53
1. Go to the Route53 dashboard underneath "Networking & Content Delivery"
2. Click "Get Started Now" underneath DNS management if you've not previously registered or worked with Route53
3. Click the "Registered Domains" on the sidebar to the left
4. Click "Register Domain" at the top, if you have an existing domain you want to transfer from a different domain registrar you can do that with the button to the right
5. Select what Top Level Domain (TLD) you want e.g. .com/.co.uk etc. and check for the availability of your desired domain, once you've found one thats available click continue
6. Fill in the registry information for the WHOIS registry
7. Accept the terms and conditions and wait for the email verification steps for the registrant email address
8. Click complete purchase

**Domain registrations can take up to three days to complete due to DNS propagation**, it can take less but this is the maximum - While its pending you can see its state in the *pending requests* section in the sidebar, after which point it will move over to *registered domains* under the *DOMAINS* section in the sidebar when its fully propagated and verified

### To create a Load-balancer
1. Go to the EC2 dashboard from the AWS Console
2. Go to "Load Balancers" under "Load Balancing" on the left hand tab
3. Click "Create Load Balancer" at the top of the page
4. Select which type of load-balancer you want *(Typically this will be an Application Load Balancer unless you have a specific speed requirement for Network load balancing, avoid the Classic Load Balancer where you can)*
5. Configure your load balancer by giving it a readable name, select whether it should be public or internal only and what IP address scheme it should use. 
6. Configure the listeners **the listeners are what port our ALB will listen on for requests** typically this will be HTTP and HTTPS for an ALB so ports 80 and 443
7. Select which availability zones you want to distribute accross to increase redundancy
8. Select which *Security group* you want to assign to the load-balancer, or you can create a new one if you want specific ports in/outbound to this ALB or one does not already exist
9. Set up target groups to point our traffic at or select an existing target group, if creating a new group add the name of the group, what protocol should be used, what port it should be pushed to and what type of target it is *(If its the ID of the instance or a specific private IP address)*
10. Set up the healthchecks endpoint, this is what will be called to evaluate if the service the loadbalancer is pointed at is healthy or not
11. Select which targets you want to add to the target group - Any targets added to the group will start to have traffic distributed to them when the loadbalancer is created
12. If you're happy with the review settings click "Create"

It may take a couple of minutes for the ALB to start up as it needs to go through each of the targets and call the healthcheck to ensure that each of the targets in the target group is in a fit state to start recieving traffic

To assess the health of the nodes in the target group:
1. Go to the EC2 dashboard from the AWS Console
2. Go to "Target Groups" under "Load Balancing" on the left hand tab
3. Select which target group you want to look at
4. Click on the "Targets" tab
5. Each of the targets will be listed with a *status* in the table to say the state of if it passed the healthcheck or not


### To add an alias to an existing domain to an AWS service
1. Go to the Route53 dashboard underneath "Networking & Content Delivery"
2. Click "Get Started Now" underneath DNS management if you've not previously registered or worked with Route53
3. Click the "Hosted zones" on the sidebar to the left
4. Select the domain name you wish to point to an existing AWS service and click *"Go to Record Sets"* which will take us to the current domain records that have been added for the domain and where we can add new records
5. Click *"Create Record Set"* to add a type A and AAAA record (If you're adding IPV6 support) and point this to your existing public IP/Hostname of your service **to alias this domain name to your public IP/Hostname**
6. Underneath the Alias list if creating an Alias on a Zone Apex record, the name of different AWS services will be listed for example the Elastic Load Balancer endpoint we previously created
7. Click create to add the record to the domain
8. Navigate to the domain in the browser to verify that the domain record has propagated

*AWS will add nameserver (NS) and a Start of Authority (SOA) record for you*

To add records to the naked domain *(often referred to as the Zone Apex record)* select the *"Alias"* radio button to be Yes. An Alias is similar to a CNAME, but the difference is that **aliases are created for the zone apex only (A and AAAA Records Only)** then in the alias targets we can point to different AWS services such as an S3 website, an Elastic Load Balancer, a Cloudfront Distribution

Why would you use an Alias over just regular A records? Because **AWS does some translation for you** in terms of it pulls specific resources from whatever you target to make sure its properly referenced also **When you use an alias record to route traffic to an AWS resource, Route 53 automatically recognizes changes in the resource.**

## CLI Demo
This section covers working with the Command Line Interface to interact with AWS resources rather than using the AWS Web Console as we have done before

A basic command to test if it is working or not is:
```
aws s3 ls
```

This will list all of the buckets that we have access to in the account. If you've installed the AWS CLI on your machine but not configured it just yet it's likely you will get the following message:
**"Unable to locate credentials. You can configure credentials by running "aws configure""**

Running this command will then ask you for an **AWS Access Key ID** and **AWS Secret Access Key** which are provided to us *when we generate an IAM user with programmatic access*, it will also ask you for a default reigon in which this users resources will be created e.g. *"eu-west-1"*

**Note: If the command succeeds but you have no S3 buckets in your account, you will get blank output**

### Basic CLI S3 Commands

To *create* a bucket via the CLI we can run:
```
aws s3 mb s3://{YOUR_BUCKET_NAME_HERE}
```

To *copy a file into a bucket* via the CLI we would run:
```
aws s3 cp YOUR_FILE_NAME s3://{YOUR_BUCKET_NAME_HERE}
```

To *list the contents of a bucket* via the CLI we run:
```
aws s3 ls s3://{YOUR_BUCKET_NAME_HERE}
```

### Access Key Management
Its good practice to invalidate console access keys when they're no longer required as it reduces our external attack surface, to remove an access key:
1. Go to the IAM dashboard
2. Go to users
3. Select the user you wish to remove a key from
4. Go to the security credentials tab
5. Scroll down to the *Access Keys* section 

We can then "Mark as inactive" to temporarily disable actions using that key or press the *x* on the line to remove that key completely. **When we delete a key there is no way to retrieve it, however we can create another** if you try and use it when its been marked as inactive or removed you will get the following error:
*An error occurred (InvalidAccessKeyId) when calling X operation: The AWS Access Key Id you have provided does not exist in our records.*

You can run *aws configure* to repoint your AWS CLI to a new key

The full documentation for the AWS CLI can be found [here](https://docs.aws.amazon.com/cli/latest/index.html)

You won't be expected to know the command line in detail for the associate level exam *however some knowledge of the basic commands such as the ones around S3 can be helpful*

### Exam Tips
* Give your users the least amount of privledge you can that still allows them to do their job
* Create groups, then assign your users to them. This helps you manage policies
* Secret access keys are only visible once, if you miss it you can just delete the key pair and regenerate it again *(however you'll need to run aws configure again to point at the new key)*
* **Don't share credentials** this opens you up to attacks from disgruntled employees without any auditing
* **Make sure you don't accidentally commit credentials to your source repository**, as people actively scan for these on GitHub and the likes to get access to your account
* Most EC2 images come with the AWS CLI already installed but you can install it on your local PC as well

## EC2 with S3 Role Lab
Look at EC2 with S3 access roles, we previously creaed a secret access key and access key id and ran AWS configure to configure a bucket.

In order to give EC2 access to another AWS service (like our EC2 instance) we need to do the following:
* Create an IAM Role
* Give the role the appropriate policies on the services it needs (S3 admin for us)
* Apply the role to the EC2 instance

Remember that roles are *the way that we grant permission to entities* that we trust, users and groups are for people, roles are for **things** so for example we could:
* Create a role that allows Lambda to talk to Kinesis
* Create a role that allows an RDS to push things to an SQS queue
* Create a role that allows Cloudwatch to be stored in Glacier

When we're creating a role, the first page asks us what kind of identity we're creating for these are:
* AWS Services - Things like S3, RDS, EC2 etc.
* Another AWS Account - These allow entities from other AWS accounts to be assigned permission to do things
* Web Identities - Are related to web based identities like Cognito or OpenID providers, for example if you wanted a user logged in from your side to be able to put things in a database and have it as being actioned *by* that user
* SAML Federation - Integrates with your corporate directory so you can give more permission to your finance department for example

When you're assigning policies for permissions to a role, always adhere to the **principle of least privalege** you want as little access as possible being given out so that it only has enough to do the job it needs to do and nothing more. The reason for this is that we have to consider what damage could be done if this entity was compromised, there also might be other considerations as well like limited access controls for certification purposes

Its useful to know the general format of policies going into the exam, an example of a policy that allows access to a bucket and its elements is:
```
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Sid": "ListObjectsInBucket",
            "Effect": "Allow",
            "Action": ["s3:ListBucket"],
            "Resource": ["arn:aws:s3:::bucket-name"]
        },
        {
            "Sid": "AllObjectActions",
            "Effect": "Allow",
            "Action": "s3:*Object",
            "Resource": ["arn:aws:s3:::bucket-name/*"]
        }
    ]
}
```

You can see that its made up of a top level version identifier, and then an array of statements that contain information about that specific rule, each statement has:
* An SID to uniquely identify the statement
* An Effect, if this should be allowed or denied on this specific resource
* An Action, can be a list of specific actions or * for them all so we can limit access or deny to a specific action
* What resource the statement is referring to, you can go as general as everything, across an entire AWS service, part of a service or even a single item

### To assign a role to a running EC2 instance
1. Go to the EC2 dashboard
2. Select the instance you want to apply the role to
3. Go to actions in the top bar, instance settings and attach/replace IAM role
4. Find or select the IAM role you want to switch to in the search bar and click apply to switch the role
5. After hitting apply it should switch out the policy, *you don't need to stop, terminate or reboot the instance to change the IAM policy*

*Note:* In the dropdown textbox when searching for roles only EC2 roles will show

If you're logged onto an EC2 instance and using CLI commands - bear in mind if you allow additional role based access **you may need to clear the credentials in .aws/ in your home folder to stop it caching the old access** otherwise you'll see access denied until the credential expires

### Exam tips
* Roles allow you to *not* use access key ids and secret access keys everywhere which are difficult to manage
* Roles are always preferable from a security perspective
* Roles are controlled by policies
* You can change a policy on a role and it will take immediate affect
* You can attach and detact roles to running EC2 instances without having to stop or terminate them

## RDS 101

## RDS Lab

## RDS Multi-AZ & Read Replicas

## Elasticache 101

## Summary